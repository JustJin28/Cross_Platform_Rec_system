{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65fc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b06224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7aaf932",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "We start by loading the preprocessed user-item matrix saved from the data cleaning step. This data will be split into training and testing sets for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83db5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "#Load the user-item matrix\n",
    "user_item = os.path.join(\"..\", \"Data\", \"Cleaned-Data\", 'user_item_filtered.csv')\n",
    "user_item_df = pd.read_csv(user_item)\n",
    "\n",
    "# Convert the DataFrame to a sparse matrix\n",
    "user_item_filtered = csr_matrix(user_item_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478a88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70825b16",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "We split the user-item interaction matrix into training and testing subsets. This allows us to train our models on a portion of the data and evaluate their performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b18040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the user-item interaction matrix into train and test subsets\n",
    "train_data, test_data = train_test_split(user_item_filtered, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a4d7e",
   "metadata": {},
   "source": [
    "### Model 1: Singular Value Decomposition (SVD)\n",
    "The first model we develop is based on SVD. SVD is a popular technique for matrix factorization in recommendation systems, especially useful for capturing latent features in sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0574e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of actual ratings: (1824,)\n",
      "Length of predicted ratings: (1824,)\n",
      "RMSE: 0.9996157395847921\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on the training data\n",
    "u, s, vt = svds(train_data, k=100)\n",
    "\n",
    "# Convert singular values to a diagonal matrix\n",
    "s_diag = np.diag(s)\n",
    "\n",
    "# Predict ratings for the test data\n",
    "predicted_ratings = np.dot(np.dot(u, s_diag), vt)\n",
    "\n",
    "# Get the non-zero indices of the test data\n",
    "test_nonzero_indices = test_data.nonzero()\n",
    "\n",
    "# Get the actual ratings from the test data\n",
    "actual_ratings = np.array(test_data[test_nonzero_indices].data).ravel()\n",
    "\n",
    "# Get the predicted ratings for the non-zero indices\n",
    "predicted_ratings_nonzero = predicted_ratings[test_nonzero_indices[0], test_nonzero_indices[1]]\n",
    "\n",
    "# Ensure predicted_ratings_nonzero is a 1D array\n",
    "predicted_ratings_nonzero = predicted_ratings_nonzero.ravel()\n",
    "\n",
    "# Debug: print lengths to check consistency\n",
    "print(\"Length of actual ratings:\", actual_ratings.shape)\n",
    "print(\"Length of predicted ratings:\", predicted_ratings_nonzero.shape)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "mse = mean_squared_error(actual_ratings, predicted_ratings_nonzero)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ea9ce",
   "metadata": {},
   "source": [
    "That was a really bad model considering the RMSE is so close to 1. Maybe some other metrics would help us here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f08e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1-score for SVD\n",
    "precision_svd = precision_score(actual_ratings, predicted_ratings_nonzero.round())\n",
    "recall_svd = recall_score(actual_ratings, predicted_ratings_nonzero.round())\n",
    "f1_svd = f1_score(actual_ratings, predicted_ratings_nonzero.round())\n",
    "\n",
    "print(\"SVD Evaluation:\")\n",
    "print(\"Precision:\", precision_svd)\n",
    "print(\"Recall:\", recall_svd)\n",
    "print(\"F1-score:\", f1_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e784c405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43099c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad0173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159f7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3006a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Truncated SVD instance\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea2a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the training data\n",
    "lsa = make_pipeline(svd)\n",
    "train_data_reduced = lsa.fit_transform(train_data)\n",
    "\n",
    "# Transform the test data using the same model\n",
    "test_data_reduced = lsa.transform(test_data)\n",
    "\n",
    "# Compute predictions (for binary you might need to threshold these)\n",
    "predicted_ratings_l2 = np.dot(train_data_reduced, svd.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7915acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.999647555897552\n"
     ]
    }
   ],
   "source": [
    "# Get the non-zero indices of the test data\n",
    "test_nonzero_indices = test_data.nonzero()\n",
    "\n",
    "# Extract actual ratings for the non-zero indices\n",
    "actual_ratings = np.array(test_data[test_nonzero_indices]).ravel()\n",
    "\n",
    "# Extract predicted ratings for the non-zero indices\n",
    "predicted_ratings_nonzero_l2 = predicted_ratings_l2[test_nonzero_indices].ravel()\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "mse = mean_squared_error(actual_ratings, predicted_ratings_nonzero_l2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dece7",
   "metadata": {},
   "source": [
    "That was a really bad model considering the RMSE is so close to 1. Maybe some other metrics would help us here? (Same explanaton as the other one.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d58627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truncated SVD Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1-score for Truncated SVD\n",
    "precision_tsvd = precision_score(actual_ratings, predicted_ratings_nonzero_l2.round())\n",
    "recall_tsvd = recall_score(actual_ratings, predicted_ratings_nonzero_l2.round())\n",
    "f1_tsvd = f1_score(actual_ratings, predicted_ratings_nonzero_l2.round())\n",
    "\n",
    "\n",
    "print(\"\\nTruncated SVD Evaluation:\")\n",
    "print(\"Precision:\", precision_tsvd)\n",
    "print(\"Recall:\", recall_tsvd)\n",
    "print(\"F1-score:\", f1_tsvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf405d",
   "metadata": {},
   "source": [
    "It seems as if both the SVD and TSVD are encountering a divide by zero error, this indicates that both models are not predicting any positive interactions correctly. This might be due to the sparsity of the user-item matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffce67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4202a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de5828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cfacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490da7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39c446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a9410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70358be8",
   "metadata": {},
   "source": [
    "### Model 2: Alternating Least Squares (ALS)\n",
    "The next model we explore is ALS. ALS is designed to handle implicit feedback by assigning confidence levels to interactions, making it well-suited for large-scale recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5797c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/25 14:54:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CollaborativeFiltering\").config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acbd51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress log warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eefcf239",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert the user-item interaction matrix to a Spark DataFrame\n",
    "user_item_df_spark = spark.createDataFrame(\n",
    "    [(i, j, float(user_item_df.iloc[i, j])) for i in range(user_item_df.shape[0]) for j in range(user_item_df.shape[1])],\n",
    "    [\"user\", \"item\", \"rating\"]\n",
    ")\n",
    "\n",
    "#Needed to reduce the size of the matrix to account for hardware constraints on my machine\n",
    "user_item_df_spark_sample = user_item_df_spark.sample(fraction=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb107c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "#(training_data_spark, test_data_spark) = user_item_df_spark.randomSplit([0.8, 0.2])\n",
    "\n",
    "(training_data_spark, test_data_spark) = user_item_df_spark_sample.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03810382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ALS model\n",
    "als = ALS(maxIter=10, regParam=0.01, userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d98034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = als.fit(training_data_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9fc1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test data\n",
    "predictions = model.transform(test_data_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667c09d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.019916126083892014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96659c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:=======================================>             (75 + 12) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|user|recommendations                                                                                                                                                                                                                   |\n",
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|12  |[{3038, 7.1372866E-20}, {2833, 2.4407156E-20}, {3590, 5.903527E-21}, {4213, 2.2550454E-21}, {943, 1.3167236E-21}, {2896, 9.147783E-22}, {1781, 4.6416783E-22}, {374, 4.5766635E-22}, {2672, 3.3773645E-22}, {3532, 2.3147842E-22}]|\n",
      "|22  |[{1176, 1.8060043E-20}, {2833, 8.592545E-21}, {4466, 3.458554E-21}, {4104, 2.7613545E-21}, {4213, 1.3976374E-21}, {2669, 1.3290012E-21}, {3399, 1.1903854E-21}, {943, 8.1608213E-22}, {3082, 6.071986E-22}, {3639, 5.810094E-22}] |\n",
      "|26  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|27  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|28  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|31  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|34  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|44  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|47  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|53  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|65  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|76  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|78  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|81  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|85  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|91  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|93  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|101 |[{3017, 1.2791663E-20}, {3399, 7.953894E-21}, {1176, 5.0825773E-21}, {307, 3.7001097E-21}, {3130, 1.3830838E-21}, {3290, 2.6321146E-22}, {2896, 2.33663E-22}, {647, 2.1705413E-22}, {2004, 1.6923529E-22}, {3403, 1.6614732E-22}] |\n",
      "|103 |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|108 |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:===============================================>     (90 + 10) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate top-k recommendations for each user\n",
    "user_recs = model.recommendForAllUsers(10)\n",
    "user_recs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ceaa742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the parameter grid\n",
    "param_grid = (ParamGridBuilder().addGrid(als.rank, [10, 50, 100]).addGrid(als.regParam, [0.01, 0.1, 1.0]).addGrid(als.maxIter, [10, 20]).build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "041a632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-validator\n",
    "cross_validator = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator,numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2172a54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Run cross-validation to find the best model\n",
    "cv_model = cross_validator.fit(training_data_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7574f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from cross-validation\n",
    "best_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f701795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test data\n",
    "best_predictions = best_model.transform(test_data_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55083c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE:  0.019916126083892014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11465:>                                                      (0 + 2) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "best_rmse = evaluator.evaluate(best_predictions)\n",
    "print(\"Best RMSE: \", best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "689d3653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11489:=========================================>         (81 + 13) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|user|recommendations                                                                                                                                                                                                                   |\n",
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|12  |[{3038, 7.1372866E-20}, {2833, 2.4407156E-20}, {3590, 5.903527E-21}, {4213, 2.2550454E-21}, {943, 1.3167236E-21}, {2896, 9.147783E-22}, {1781, 4.6416783E-22}, {374, 4.5766635E-22}, {2672, 3.3773645E-22}, {3532, 2.3147842E-22}]|\n",
      "|22  |[{1176, 1.8060043E-20}, {2833, 8.592545E-21}, {4466, 3.458554E-21}, {4104, 2.7613545E-21}, {4213, 1.3976374E-21}, {2669, 1.3290012E-21}, {3399, 1.1903854E-21}, {943, 8.1608213E-22}, {3082, 6.071986E-22}, {3639, 5.810094E-22}] |\n",
      "|26  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|27  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|28  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|31  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|34  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|44  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|47  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|53  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|65  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|76  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|78  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|81  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|85  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|91  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|93  |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|101 |[{3017, 1.2791663E-20}, {3399, 7.953894E-21}, {1176, 5.0825773E-21}, {307, 3.7001097E-21}, {3130, 1.3830838E-21}, {3290, 2.6321146E-22}, {2896, 2.33663E-22}, {647, 2.1705413E-22}, {2004, 1.6923529E-22}, {3403, 1.6614732E-22}] |\n",
      "|103 |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "|108 |[{99, 0.0}, {98, 0.0}, {97, 0.0}, {96, 0.0}, {95, 0.0}, {94, 0.0}, {93, 0.0}, {92, 0.0}, {91, 0.0}, {90, 0.0}]                                                                                                                    |\n",
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate top-k recommendations for each user using the best model\n",
    "best_user_recs = best_model.recommendForAllUsers(10)\n",
    "best_user_recs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3200892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc0087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "428c0e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert predictions to Pandas DataFrame for easier evaluation\n",
    "predictions_df = best_predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b4c5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round predictions to get binary values\n",
    "predictions_df['prediction'] = predictions_df['prediction'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1d044f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.0\n",
      "Recall:  0.0\n",
      "F1-Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1-score\n",
    "precision = precision_score(predictions_df['rating'], predictions_df['prediction'], zero_division=1)\n",
    "recall = recall_score(predictions_df['rating'], predictions_df['prediction'], zero_division=1)\n",
    "f1 = f1_score(predictions_df['rating'], predictions_df['prediction'], zero_division=1)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b3e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608d5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35d009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab7043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0be6505e",
   "metadata": {},
   "source": [
    "### Model 3: Deep Learning\n",
    "The final model we implement is a deep learning model using TensorFlow. Deep learning models can capture complex, non-linear relationships in the data, providing a flexible approach to learning user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f418f8cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Attempting with deep learning\n",
    "# Prepare the data for the deep learning model\n",
    "train_data_nonzero = train_data.nonzero()\n",
    "test_data_nonzero = test_data.nonzero()\n",
    "\n",
    "train_user = train_data_nonzero[0]\n",
    "train_item = train_data_nonzero[1]\n",
    "train_rating = train_data[train_user, train_item].A1\n",
    "\n",
    "test_user = test_data_nonzero[0]\n",
    "test_item = test_data_nonzero[1]\n",
    "test_rating = test_data[test_user, test_item].A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e8cf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model\n",
    "num_users = user_item_df.shape[0]\n",
    "num_items = user_item_df.shape[1]\n",
    "\n",
    "user_input = Input(shape=(1,))\n",
    "item_input = Input(shape=(1,))\n",
    "\n",
    "user_embedding = Embedding(num_users, 50)(user_input)\n",
    "item_embedding = Embedding(num_items, 50)(item_input)\n",
    "\n",
    "user_vector = Flatten()(user_embedding)\n",
    "item_vector = Flatten()(item_embedding)\n",
    "\n",
    "concat = Concatenate()([user_vector, item_vector])\n",
    "\n",
    "dense = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(concat)\n",
    "dropout = Dropout(0.5)(dense)\n",
    "output = Dense(1)(dropout)\n",
    "\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d38b0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5dca1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3745 - val_loss: 0.1430\n",
      "Epoch 2/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1023 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0200 - val_loss: 8.5628e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 3.0396e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 2.8840e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 2.0031e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 2.4602e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 5.4395e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 5.3854e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a0cb5610>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([train_user, train_item], train_rating, epochs=50, batch_size=64, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8756d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for the test data\n",
    "predicted_ratings = model.predict([test_user, test_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf0a68ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Model RMSE: 0.018339885321576637\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_rating, predicted_ratings))\n",
    "print(\"Deep Learning Model RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a51ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Model Evaluation:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1-score\n",
    "predicted_ratings_rounded = np.round(predicted_ratings).astype(int)\n",
    "\n",
    "precision_dl = precision_score(test_rating, predicted_ratings_rounded, zero_division=1)\n",
    "recall_dl = recall_score(test_rating, predicted_ratings_rounded, zero_division=1)\n",
    "f1_dl = f1_score(test_rating, predicted_ratings_rounded, zero_division=1)\n",
    "\n",
    "print(\"Deep Learning Model Evaluation:\")\n",
    "print(\"Precision:\", precision_dl)\n",
    "print(\"Recall:\", recall_dl)\n",
    "print(\"F1-score:\", f1_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce07b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a449f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f740aa4",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We summarize the performance of each model, highlight their strengths and weaknesses, and outline the next steps for improving our recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25afd6",
   "metadata": {},
   "source": [
    "Summary of Model Evaluations\n",
    "\n",
    "In this project, we developed and evaluated four different models to predict user preferences for books, music, and movies. Each model’s performance was assessed using various metrics, and the results are summarized below.\n",
    "\n",
    "1. Singular Value Decomposition (SVD)\n",
    "\n",
    "\t•\tLength of Actual Ratings: 1824\n",
    "    \n",
    "\t•\tLength of Predicted Ratings: 1824\n",
    "    \n",
    "\t•\tRoot Mean Squared Error (RMSE): 0.9996\n",
    "    \n",
    "\t•\tPrecision: 0.0\n",
    "    \n",
    "\t•\tRecall: 0.0\n",
    "    \n",
    "\t•\tF1-Score: 0.0\n",
    "    \n",
    "\n",
    "Analysis:\n",
    "The SVD model achieved an RMSE of approximately 0.9996, indicating poor performance in predicting user ratings. The precision, recall, and F1-score were all 0.0, suggesting that the model failed to correctly identify relevant items. This poor performance could be due to the model’s assumption of linearity in latent factors, which may not hold true in our data.\n",
    "\n",
    "2. Truncated SVD\n",
    "\n",
    "\t•\tRoot Mean Squared Error (RMSE): 0.9996\n",
    "    \n",
    "\t•\tPrecision: 0.0\n",
    "    \n",
    "\t•\tRecall: 0.0\n",
    "    \n",
    "\t•\tF1-Score: 0.0\n",
    "    \n",
    "\n",
    "Analysis:\n",
    "The Truncated SVD model also resulted in an RMSE of approximately 0.9996, similar to the basic SVD model. The precision, recall, and F1-score were again all 0.0, indicating that this model did not perform well in our recommendation context. The linear assumption of latent factors likely affected its performance.\n",
    "\n",
    "3. Alternating Least Squares (ALS)\n",
    "\n",
    "\t•\tRoot Mean Squared Error (RMSE): 0.0199\n",
    "    \n",
    "\t•\tPrecision: 1.0\n",
    "    \n",
    "\t•\tRecall: 0.0\n",
    "    \n",
    "\t•\tF1-Score: 0.0\n",
    "    \n",
    "\n",
    "Analysis:\n",
    "The ALS model achieved a significantly lower RMSE of 0.0199, suggesting better predictive accuracy compared to the SVD models. However, the precision was 1.0 while the recall and F1-score were 0.0, indicating that the model identified very few items as relevant (leading to precision) but missed many actual relevant items (resulting in zero recall). This suggests potential underfitting, likely due to the high sparsity of the user-item matrix. Further hyperparameter tuning is needed to improve the model’s performance.\n",
    "\n",
    "4. Deep Learning Model\n",
    "\n",
    "\t•\tRoot Mean Squared Error (RMSE): 0.0183\n",
    "    \n",
    "\t•\tPrecision: 1.0\n",
    "    \n",
    "\t•\tRecall: 1.0\n",
    "    \n",
    "\t•\tF1-Score: 1.0\n",
    "    \n",
    "\n",
    "Analysis:\n",
    "The deep learning model achieved the lowest RMSE of 0.0183, indicating excellent predictive accuracy. However, the precision, recall, and F1-score were all 1.0, which is typically unrealistic and suggests that the model is overfitting to the training data. This overfitting means that the model may not generalize well to new, unseen data.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "\n",
    "\t•\tSVD and Truncated SVD: Both SVD models failed to perform well due to their assumption of linear latent factors, resulting in high RMSE and zero precision, recall, and F1-score.\n",
    "    \n",
    "\t•\tALS: The ALS model showed promising RMSE results, but the issue of underfitting in the top-k recommendations highlights the need for further tuning and addressing the sparsity of the data.\n",
    "    \n",
    "\t•\tDeep Learning: The deep learning model achieved the best RMSE, but its perfect scores in precision, recall, and F1-score indicate severe overfitting, which limits its practicality.\n",
    "    \n",
    "\n",
    "Recommendations\n",
    "\n",
    "\n",
    "\t•\tHyperparameter Tuning: Further tuning of the ALS model is essential to improve its performance and mitigate the underfitting issue.\n",
    "    \n",
    "\t•\tOverfitting Mitigation: For the deep learning model, applying regularization techniques, dropout, and cross-validation will help reduce overfitting and improve generalization to new data.\n",
    "    \n",
    "\t•\tHybrid Approaches: Exploring hybrid recommendation systems that combine collaborative filtering with content-based methods can leverage additional user and item metadata, potentially improving overall recommendation quality.\n",
    "    \n",
    "\n",
    "By iterating on these models and incorporating the suggested improvements, we can develop a more accurate and reliable cross-platform recommendation system for books, music, and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce015eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae9c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d1e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab7f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca031c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d51f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
